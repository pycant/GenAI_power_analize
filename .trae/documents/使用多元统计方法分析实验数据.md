我将创建一个新的分析脚本 `scripts/multivariate_statistic_analize.py`，使用以下 5 种多元统计方法对实验数据进行深度分析。

### **分析方法选择 (基于您的目录)**

1.  **多元相关性分析 (Multivariate Correlation Analysis)**
    *   **对应目录**: 第一部分 - 2. 多元概率论基础 (协方差与相关结构)
    *   **目的**: 探索延迟、吞吐量、能耗、显存占用、质量得分等指标之间的线性相关结构，识别强相关的指标对。

2.  **多元方差分析 (MANOVA)**
    *   **对应目录**: 第二部分 - 3. 均值向量推断 (多元方差分析)
    *   **目的**: 检验不同的“模型”和“任务类型”是否对 {时延, 吞吐, 能耗, 质量} 这一组因变量向量有显著的整体影响。这比单独做多次 ANOVA 更能控制一类错误率。

3.  **主成分分析 (PCA)**
    *   **对应目录**: 第三部分 - 5. 主成分分析
    *   **目的**: 将多维性能指标降维为 2-3 个主成分（如“效率因子”、“资源因子”），在二维平面上可视化 16 次实验运行的分布，直观展示模型间的性能差异。

4.  **层次聚类分析 (Hierarchical Clustering)**
    *   **对应目录**: 第四部分 - 10. 聚类分析
    *   **目的**: 不预设类别，根据性能特征对实验结果进行聚类，绘制树状图 (Dendrogram)，观察哪些模型在哪些任务上的表现是相似的（例如：某两个模型在代码任务上可能被聚为一类）。

5.  **典型相关分析 (Canonical Correlation Analysis, CCA)**
    *   **对应目录**: 第五部分 - 12. 典型相关分析
    *   **目的**: 研究“资源消耗组变量”（显存、能耗、利用率）与“性能产出组变量”（吞吐、延迟、质量）之间的整体相关性，探索投入与产出之间的内在联系。

### **实现计划**

1.  **数据加载与预处理**
    *   复用 `analyze_experiments_1.py` 的数据读取逻辑。
    *   合并 `results.csv` 与从 JSON 提取的细粒度质量指标。
    *   数据清洗（缺失值填充）与标准化（Z-Score Standardization）。

2.  **编写分析脚本 (`scripts/multivariate_statistic_analize.py`)**
    *   使用 `pandas` 处理数据。
    *   使用 `seaborn`/`matplotlib` 绘图。
    *   使用 `scipy.stats`, `statsmodels.multivariate` (MANOVA), `sklearn.decomposition` (PCA), `sklearn.cluster` (Clustering), `sklearn.cross_decomposition` (CCA) 进行统计建模。

3.  **生成输出**
    *   **可视化图表**: 保存至 `results/experiments_1/figures_multivariate/` (如 PCA 散点图、相关性热力图、聚类树状图)。
    *   **分析报告**: 生成 `results/experiments_1/multivariate_report.md`，包含统计量（Wilks' lambda, F值, 解释方差比等）和文字解读。

4.  **验证**
    *   运行脚本并检查生成的报告和图表。
