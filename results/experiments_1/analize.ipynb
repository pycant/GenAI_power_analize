{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60a8d9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib import font_manager as fm\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "def find_project_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / \"data\").is_dir() and (p / \"results\").is_dir():\n",
    "            return p\n",
    "    return start  # 兜底：找不到就用当前目录\n",
    "\n",
    "try:\n",
    "    here = Path(__file__).resolve().parent  # 脚本环境\n",
    "except NameError:\n",
    "    here = Path.cwd()  # Notebook 环境\n",
    "    \n",
    "# 配置路径\n",
    "BASE_DIR = find_project_root(here)\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\", \"experiments_1\")\n",
    "RESULTS_DIR = os.path.join(BASE_DIR, \"results\", \"experiments_1\")\n",
    "FIGURES_DIR = os.path.join(RESULTS_DIR, \"figures\")\n",
    "os.makedirs(FIGURES_DIR, exist_ok=True)\n",
    "\n",
    "HAS_CHINESE_FONT = False\n",
    "FONT_PROP = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "930d146d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用字体: Microsoft YaHei\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def _configure_io_and_fonts():\n",
    "    global HAS_CHINESE_FONT\n",
    "    if hasattr(sys.stdout, \"reconfigure\"):\n",
    "        try:\n",
    "            sys.stdout.reconfigure(encoding=\"utf-8\")\n",
    "        except Exception:\n",
    "            pass\n",
    "    if hasattr(sys.stderr, \"reconfigure\"):\n",
    "        try:\n",
    "            sys.stderr.reconfigure(encoding=\"utf-8\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    candidates = [\n",
    "        \"Microsoft YaHei\",\n",
    "        \"SimHei\",\n",
    "        \"Noto Sans CJK SC\",\n",
    "        \"Source Han Sans CN\",\n",
    "        \"Arial Unicode MS\",\n",
    "    ]\n",
    "    available = {f.name for f in fm.fontManager.ttflist}\n",
    "    chosen = None\n",
    "    for name in candidates:\n",
    "        if name in available:\n",
    "            chosen = name\n",
    "            break\n",
    "    if not chosen:\n",
    "        font_paths = []\n",
    "        try:\n",
    "            font_paths = fm.findSystemFonts()\n",
    "        except Exception:\n",
    "            font_paths = []\n",
    "        win_font_dir = r\"C:\\\\Windows\\\\Fonts\"\n",
    "        if os.path.isdir(win_font_dir):\n",
    "            try:\n",
    "                font_paths += [\n",
    "                    os.path.join(win_font_dir, f)\n",
    "                    for f in os.listdir(win_font_dir)\n",
    "                    if f.lower().endswith((\".ttf\", \".ttc\", \".otf\"))\n",
    "                ]\n",
    "            except Exception:\n",
    "                pass\n",
    "        desired = set(candidates + [\"SimSun\", \"NSimSun\", \"Microsoft YaHei UI\"]) \n",
    "        for p in font_paths:\n",
    "            try:\n",
    "                nm = fm.FontProperties(fname=p).get_name()\n",
    "            except Exception:\n",
    "                continue\n",
    "            if nm in desired:\n",
    "                try:\n",
    "                    fm.fontManager.addfont(p)\n",
    "                except Exception:\n",
    "                    pass\n",
    "                chosen = nm\n",
    "                break\n",
    "    if chosen:\n",
    "        mpl.rcParams['font.family'] = chosen\n",
    "        mpl.rcParams['font.sans-serif'] = [chosen]\n",
    "        mpl.rcParams['axes.unicode_minus'] = False\n",
    "        HAS_CHINESE_FONT = True\n",
    "        print(f\"使用字体: {chosen}\")\n",
    "        try:\n",
    "            font_path = fm.findfont(chosen)\n",
    "            globals()['FONT_PROP'] = fm.FontProperties(fname=font_path)\n",
    "        except Exception:\n",
    "            globals()['FONT_PROP'] = None\n",
    "    else:\n",
    "        HAS_CHINESE_FONT = False\n",
    "\n",
    "_configure_io_and_fonts()\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"加载汇总数据与统计数据\"\"\"\n",
    "    res_path = os.path.join(DATA_DIR, \"summary\", \"results.csv\")\n",
    "    stats_path = os.path.join(DATA_DIR, \"summary\", \"stats.csv\")\n",
    "    \n",
    "    if not os.path.exists(res_path) or not os.path.exists(stats_path):\n",
    "        print(\"数据文件未找到，请确认 experiments_1 是否执行完成。\")\n",
    "        return None, None\n",
    "        \n",
    "    df_res = pd.read_csv(res_path)\n",
    "    df_stats = pd.read_csv(stats_path)\n",
    "    \n",
    "    # 补充缺失值处理\n",
    "    df_res['bartscore'] = pd.to_numeric(df_res['bartscore'], errors='coerce')\n",
    "    df_res['tps'] = pd.to_numeric(df_res['toks_per_s'], errors='coerce')\n",
    "    df_res['latency'] = pd.to_numeric(df_res['latency_s'], errors='coerce')\n",
    "    df_res['energy'] = pd.to_numeric(df_res['gpu_energy_j'], errors='coerce')\n",
    "    \n",
    "    return df_res, df_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46aa29e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>run</th>\n",
       "      <th>code_score</th>\n",
       "      <th>creative_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deepseek-r1:8b</td>\n",
       "      <td>code</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deepseek-r1:8b</td>\n",
       "      <td>creative</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek-r1:8b</td>\n",
       "      <td>qa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deepseek-r1:8b</td>\n",
       "      <td>summary</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gemma3:4b</td>\n",
       "      <td>code</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gemma3:4b</td>\n",
       "      <td>creative</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gemma3:4b</td>\n",
       "      <td>qa</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gemma3:4b</td>\n",
       "      <td>summary</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>qwen3:4b</td>\n",
       "      <td>code</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>qwen3:4b</td>\n",
       "      <td>creative</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>qwen3:4b</td>\n",
       "      <td>qa</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>qwen3:4b</td>\n",
       "      <td>summary</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>qwen3:8b</td>\n",
       "      <td>code</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>qwen3:8b</td>\n",
       "      <td>creative</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>qwen3:8b</td>\n",
       "      <td>qa</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>qwen3:8b</td>\n",
       "      <td>summary</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model      task run  code_score  creative_score\n",
       "0   deepseek-r1:8b      code   9         1.0             0.0\n",
       "1   deepseek-r1:8b  creative  13         0.0             1.0\n",
       "2   deepseek-r1:8b        qa   1         0.0             0.0\n",
       "3   deepseek-r1:8b   summary   5         0.0             0.0\n",
       "4        gemma3:4b      code  10         1.0             0.0\n",
       "5        gemma3:4b  creative  14         0.0             1.0\n",
       "6        gemma3:4b        qa   2         0.0             0.0\n",
       "7        gemma3:4b   summary   6         0.0             0.0\n",
       "8         qwen3:4b      code  12         1.0             0.0\n",
       "9         qwen3:4b  creative  16         0.0             1.0\n",
       "10        qwen3:4b        qa   4         0.0             0.0\n",
       "11        qwen3:4b   summary   8         0.0             0.0\n",
       "12        qwen3:8b      code  11         1.0             0.0\n",
       "13        qwen3:8b  creative  15         0.0             1.0\n",
       "14        qwen3:8b        qa   3         0.0             0.0\n",
       "15        qwen3:8b   summary   7         0.0             0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_quality_details():\n",
    "    \"\"\"从原始JSON加载更细粒度的质量指标\"\"\"\n",
    "    raw_dir = os.path.join(DATA_DIR, \"raw\")\n",
    "    records = []\n",
    "    \n",
    "    for model in os.listdir(raw_dir):\n",
    "        model_path = os.path.join(raw_dir, model)\n",
    "        if not os.path.isdir(model_path):\n",
    "            continue\n",
    "            \n",
    "        for fname in os.listdir(model_path):\n",
    "            if not fname.endswith(\".json\"):\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                with open(os.path.join(model_path, fname), \"r\", encoding=\"utf-8\") as f:\n",
    "                    data = json.load(f)\n",
    "                    \n",
    "                q = data.get(\"quality\", {}) or {}\n",
    "                # 提取Code指标\n",
    "                code_score = 0\n",
    "                if data.get(\"prompt\", \"\").find(\"fibonacci\") >= 0 or \"code\" in fname:\n",
    "                    if q.get(\"code\") and q[\"code\"].get(\"code_compiles\"):\n",
    "                        code_score = 1.0\n",
    "                \n",
    "                # 提取Creative指标\n",
    "                creative_score = 0\n",
    "                if q.get(\"creative\"):\n",
    "                    creative_score = q[\"creative\"].get(\"distinct_2\", 0)\n",
    "                \n",
    "                records.append({\n",
    "                    \"model\": data.get(\"model\"),\n",
    "                    \"task\": fname.split(\"_\")[0], # 假设命名规则 task_load_run.json\n",
    "                    \"run\": fname.split(\"_\")[-1].replace(\".json\", \"\").replace(\"r\", \"\"),\n",
    "                    \"code_score\": code_score,\n",
    "                    \"creative_score\": creative_score\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {fname}: {e}\")\n",
    "                \n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "load_quality_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53466f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_composite_metrics(df):\n",
    "    \"\"\"计算复合质效指标\"\"\"\n",
    "    # 归一化 (Min-Max Scaling)\n",
    "    def normalize(series, mode='max'):\n",
    "        if series.max() == series.min():\n",
    "            return 1.0 if mode=='max' else 0.0\n",
    "        if mode == 'min': # 越小越好 (如延迟、能耗) -> 越大越好\n",
    "            return (series.max() - series) / (series.max() - series.min())\n",
    "        return (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "    # 按任务分组归一化，避免跨任务比较的不公平\n",
    "    df['norm_tps'] = df.groupby('task')['tps'].transform(lambda x: normalize(x, 'max'))\n",
    "    df['norm_lat'] = df.groupby('task')['latency'].transform(lambda x: normalize(x, 'min'))\n",
    "    df['norm_energy'] = df.groupby('task')['energy'].transform(lambda x: normalize(x, 'min'))\n",
    "    \n",
    "    # 质量分数归一化\n",
    "    # 对于 QA/Summary 使用 BARTScore\n",
    "    # 对于 Code 使用 code_score (编译通过率)\n",
    "    # 对于 Creative 使用 distinct-2\n",
    "    \n",
    "    df['quality_raw'] = df['bartscore'].fillna(0) # 暂用 BARTScore\n",
    "    # 如果有 code/creative 分数，覆盖 quality_raw\n",
    "    if 'code_score' in df.columns:\n",
    "        df.loc[df['task']=='code', 'quality_raw'] = df['code_score']\n",
    "    if 'creative_score' in df.columns:\n",
    "        df.loc[df['task']=='creative', 'quality_raw'] = df['creative_score']\n",
    "        \n",
    "    df['norm_quality'] = df.groupby('task')['quality_raw'].transform(lambda x: normalize(x, 'max'))\n",
    "    \n",
    "    # 效能得分 (Efficiency Score): 40% 吞吐 + 30% 延迟 + 30% 能耗优\n",
    "    df['efficiency_score'] = 0.4 * df['norm_tps'] + 0.3 * df['norm_lat'] + 0.3 * df['norm_energy']\n",
    "    \n",
    "    # 质效比 (Q/E Ratio)\n",
    "    # 避免分母为0，加 epsilon\n",
    "    df['qe_ratio'] = (df['norm_quality'] + 0.01) / (1.01 - df['efficiency_score'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def plot_charts(df):\n",
    "    \"\"\"生成可视化图表\"\"\"\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    \n",
    "    # 1. 吞吐量 vs 延迟 (散点图)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=df, x='latency', y='tps', hue='model', style='task', s=100)\n",
    "    ax = plt.gca()\n",
    "    if HAS_CHINESE_FONT:\n",
    "        ax.set_title(\"吞吐量 vs 延迟分布\", fontproperties=FONT_PROP)\n",
    "        ax.set_xlabel(\"延迟 (秒) [越低越好]\", fontproperties=FONT_PROP)\n",
    "        ax.set_ylabel(\"吞吐量 (tokens/s) [越高越好]\", fontproperties=FONT_PROP)\n",
    "    else:\n",
    "        ax.set_title(\"Throughput vs Latency\")\n",
    "        ax.set_xlabel(\"Latency (s) [lower better]\")\n",
    "        ax.set_ylabel(\"Throughput (tokens/s) [higher better]\")\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, \"throughput_vs_latency.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. 能耗 vs 质量 (散点图)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # 过滤掉质量为0的点（可能无BARTScore）\n",
    "    df_q = df[df['quality_raw'] != 0]\n",
    "    sns.scatterplot(data=df_q, x='energy', y='quality_raw', hue='model', style='task', s=100)\n",
    "    ax = plt.gca()\n",
    "    if HAS_CHINESE_FONT:\n",
    "        ax.set_title(\"能耗 vs 质量分布\", fontproperties=FONT_PROP)\n",
    "        ax.set_xlabel(\"GPU能耗 (J) [越低越好]\", fontproperties=FONT_PROP)\n",
    "        ax.set_ylabel(\"质量得分 (BARTScore/Distinct/Compile) [越高越好]\", fontproperties=FONT_PROP)\n",
    "    else:\n",
    "        ax.set_title(\"Energy vs Quality\")\n",
    "        ax.set_xlabel(\"GPU Energy (J) [lower better]\")\n",
    "        ax.set_ylabel(\"Quality score [higher better]\")\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, \"energy_vs_quality.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. 质效比对比 (柱状图)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=df, x='task', y='qe_ratio', hue='model', errorbar=None)\n",
    "    ax = plt.gca()\n",
    "    if HAS_CHINESE_FONT:\n",
    "        ax.set_title(\"各模型在不同任务下的质效比 (Q/E Ratio)\", fontproperties=FONT_PROP)\n",
    "        ax.set_ylabel(\"质效比 (越高越优)\", fontproperties=FONT_PROP)\n",
    "    else:\n",
    "        ax.set_title(\"Q/E Ratio across tasks\")\n",
    "        ax.set_ylabel(\"Q/E Ratio [higher better]\")\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, \"quality_efficiency_ratio.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. 雷达图 (各维度平均表现)\n",
    "    # 按模型聚合\n",
    "    radar_df = df.groupby('model')[[ 'norm_tps', 'norm_lat', 'norm_energy', 'norm_quality']].mean().reset_index()\n",
    "    \n",
    "    categories = ['吞吐', '延迟(优)', '能耗(优)', '质量'] if HAS_CHINESE_FONT else ['Throughput', 'Latency(+)', 'Energy(+)', 'Quality']\n",
    "    N = len(categories)\n",
    "    \n",
    "    angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(111, polar=True)\n",
    "    \n",
    "    for i, row in radar_df.iterrows():\n",
    "        values = row[['norm_tps', 'norm_lat', 'norm_energy', 'norm_quality']].values.flatten().tolist()\n",
    "        values += values[:1]\n",
    "        ax.plot(angles, values, linewidth=1, linestyle='solid', label=row['model'])\n",
    "        ax.fill(angles, values, alpha=0.1)\n",
    "        \n",
    "    ax.set_xticks(angles[:-1])\n",
    "    if HAS_CHINESE_FONT:\n",
    "        ax.set_xticklabels(categories, fontproperties=FONT_PROP)\n",
    "        ax.set_title(\"模型综合能力雷达图 (归一化指标)\", fontproperties=FONT_PROP)\n",
    "    else:\n",
    "        ax.set_xticklabels(categories)\n",
    "        ax.set_title(\"Model capability radar (normalized)\")\n",
    "    leg = plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "    if HAS_CHINESE_FONT and FONT_PROP is not None:\n",
    "        for text in leg.get_texts():\n",
    "            text.set_fontproperties(FONT_PROP)\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, \"radar_chart.png\"))\n",
    "    plt.close()\n",
    "\n",
    "def generate_report(df, df_stats):\n",
    "    \"\"\"生成Markdown分析报告\"\"\"\n",
    "    best_model_qe = df.groupby('model')['qe_ratio'].mean().idxmax()\n",
    "    best_model_tps = df.groupby('model')['tps'].mean().idxmax()\n",
    "    best_model_energy = df.groupby('model')['energy'].mean().idxmin()\n",
    "    \n",
    "    report_content = f\"\"\"# 实验数据分析报告：基于大语言模型的多维质效比评估\n",
    "\n",
    "## 1. 实验概况\n",
    "- **实验批次**: experiments_1\n",
    "- **生成时间**: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "- **包含模型**: {\", \".join(df['model'].unique())}\n",
    "- **包含任务**: {\", \".join(df['task'].unique())}\n",
    "- **总样本数**: {len(df)}\n",
    "\n",
    "## 2. 关键发现\n",
    "- **综合质效比最优**: **{best_model_qe}**，在质量与资源消耗之间取得了最佳平衡。\n",
    "- **吞吐性能最强**: **{best_model_tps}**，适合对延迟敏感的高并发场景。\n",
    "- **最节能模型**: **{best_model_energy}**，适合端侧或低功耗场景。\n",
    "\n",
    "## 3. 详细指标分析\n",
    "\n",
    "### 3.1 效率维度\n",
    "- **吞吐量 (TPS)**: \n",
    "  - 均值: {df['tps'].mean():.2f} tokens/s\n",
    "  - 峰值: {df['tps'].max():.2f} tokens/s (由 {df.loc[df['tps'].idxmax(), 'model']} 贡献)\n",
    "- **能耗 (Energy)**:\n",
    "  - 平均单次请求能耗: {df['energy'].mean():.2f} J\n",
    "\n",
    "### 3.2 质量维度\n",
    "- **BARTScore (QA/Summary)**: \n",
    "  - 均值: {df[df['bartscore']!=0]['bartscore'].mean():.4f}\n",
    "  - 最优: {df['bartscore'].max():.4f}\n",
    "\n",
    "### 3.3 质效比 (Q/E Ratio)\n",
    "- 该指标综合了归一化的质量得分与效率成本（1 - 效率得分）。\n",
    "- 排名如下：\n",
    "{df.groupby('model')['qe_ratio'].mean().sort_values(ascending=False).to_markdown()}\n",
    "\n",
    "## 4. 可视化图表\n",
    "### 4.1 吞吐量 vs 延迟\n",
    "![Throughput vs Latency](figures/throughput_vs_latency.png)\n",
    "\n",
    "### 4.2 能耗 vs 质量\n",
    "![Energy vs Quality](figures/energy_vs_quality.png)\n",
    "\n",
    "### 4.3 质效比对比\n",
    "![Q/E Ratio](figures/quality_efficiency_ratio.png)\n",
    "\n",
    "### 4.4 综合雷达图\n",
    "![Radar Chart](figures/radar_chart.png)\n",
    "\n",
    "## 5. 数据摘要表\n",
    "{df_stats.to_markdown(index=False)}\n",
    "\n",
    "---\n",
    "*注：本报告由自动化分析脚本生成。*\n",
    "\"\"\"\n",
    "    with open(os.path.join(RESULTS_DIR, \"report.md\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(report_content)\n",
    "    print(f\"报告已生成: {os.path.join(RESULTS_DIR, 'report.md')}\")\n",
    "\n",
    "def _std(X):\n",
    "    m = X.mean(axis=0)\n",
    "    s = X.std(axis=0)\n",
    "    s[s==0] = 1\n",
    "    return (X - m) / s\n",
    "\n",
    "def run_pca(df):\n",
    "    feats = ['norm_tps','norm_lat','norm_energy','norm_quality']\n",
    "    X = df[feats].values\n",
    "    Z = _std(X)\n",
    "    U,S,Vt = np.linalg.svd(Z, full_matrices=False)\n",
    "    comps = Vt\n",
    "    scores = Z @ comps.T\n",
    "    evr = (S**2) / (S**2).sum()\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.scatterplot(x=scores[:,0], y=scores[:,1], hue=df['model'], style=df['task'], s=100)\n",
    "    ax = plt.gca()\n",
    "    if HAS_CHINESE_FONT:\n",
    "        ax.set_title(\"主成分分析 (PC1-PC2)\", fontproperties=FONT_PROP)\n",
    "        ax.set_xlabel(\"PC1\", fontproperties=FONT_PROP)\n",
    "        ax.set_ylabel(\"PC2\", fontproperties=FONT_PROP)\n",
    "    else:\n",
    "        ax.set_title(\"PCA (PC1-PC2)\")\n",
    "        ax.set_xlabel(\"PC1\")\n",
    "        ax.set_ylabel(\"PC2\")\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, \"pca_scatter.png\"))\n",
    "    plt.close()\n",
    "    return evr, scores, comps\n",
    "\n",
    "def run_mds(df):\n",
    "    feats = ['norm_tps','norm_lat','norm_energy','norm_quality']\n",
    "    M = df.groupby('model')[feats].mean().reset_index()\n",
    "    X = M[feats].values\n",
    "    Z = _std(X)\n",
    "    n = Z.shape[0]\n",
    "    D2 = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            d = Z[i]-Z[j]\n",
    "            D2[i,j] = np.dot(d,d)\n",
    "    J = np.eye(n) - np.ones((n,n))/n\n",
    "    B = -0.5 * J @ D2 @ J\n",
    "    w, V = np.linalg.eigh(B)\n",
    "    idx = np.argsort(w)[::-1]\n",
    "    w = w[idx]\n",
    "    V = V[:,idx]\n",
    "    coords = V[:, :2] * np.sqrt(np.maximum(w[:2], 0))\n",
    "    plt.figure(figsize=(8,6))\n",
    "    for i,name in enumerate(M['model']):\n",
    "        plt.scatter(coords[i,0], coords[i,1], s=120)\n",
    "        plt.text(coords[i,0], coords[i,1], name)\n",
    "    if HAS_CHINESE_FONT:\n",
    "        plt.title(\"多维标度 (模型)\", fontproperties=FONT_PROP)\n",
    "    else:\n",
    "        plt.title(\"MDS (models)\")\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, \"mds_models.png\"))\n",
    "    plt.close()\n",
    "    return M['model'].tolist(), coords\n",
    "\n",
    "def run_kmeans(df, k=3, max_iter=100):\n",
    "    feats = ['norm_tps','norm_lat','norm_energy','norm_quality']\n",
    "    X = df[feats].values\n",
    "    Z = _std(X)\n",
    "    rng = np.random.default_rng(42)\n",
    "    centers = Z[rng.choice(Z.shape[0], size=k, replace=False)]\n",
    "    for _ in range(max_iter):\n",
    "        dists = ((Z[:,None,:]-centers[None,:,:])**2).sum(axis=2)\n",
    "        labels = dists.argmin(axis=1)\n",
    "        new_centers = np.vstack([Z[labels==i].mean(axis=0) if (labels==i).any() else centers[i] for i in range(k)])\n",
    "        if np.allclose(new_centers, centers):\n",
    "            break\n",
    "        centers = new_centers\n",
    "    evr, scores, comps = run_pca(df)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.scatterplot(x=scores[:,0], y=scores[:,1], hue=labels, palette='tab10', style=df['task'], s=100)\n",
    "    if HAS_CHINESE_FONT:\n",
    "        plt.title(\"K-means 聚类 (PC 空间)\", fontproperties=FONT_PROP)\n",
    "    else:\n",
    "        plt.title(\"K-means clusters (PC space)\")\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, \"kmeans_pca.png\"))\n",
    "    plt.close()\n",
    "    return labels\n",
    "\n",
    "def run_cca(df):\n",
    "    sub = df[df['task'].isin(['qa','summary'])].copy()\n",
    "    sub = sub.dropna(subset=['bartscore'])\n",
    "    X = sub[['norm_tps','norm_lat','norm_energy']].values\n",
    "    Y = sub[['bartscore']].values\n",
    "    X = X - X.mean(axis=0)\n",
    "    Y = Y - Y.mean(axis=0)\n",
    "    Cxx = X.T @ X / max(X.shape[0]-1,1)\n",
    "    Cyy = Y.T @ Y / max(Y.shape[0]-1,1)\n",
    "    Cxy = X.T @ Y / max(X.shape[0]-1,1)\n",
    "    Ex = np.linalg.eigh(Cxx)\n",
    "    Ey = np.linalg.eigh(Cyy)\n",
    "    vx = Ex[1]\n",
    "    vy = Ey[1]\n",
    "    lx = Ex[0]\n",
    "    ly = Ey[0]\n",
    "    Wx = vx @ np.diag(1/np.sqrt(np.maximum(lx,1e-12))) @ vx.T\n",
    "    Wy = vy @ np.diag(1/np.sqrt(np.maximum(ly,1e-12))) @ vy.T\n",
    "    M = Wx @ Cxy @ Wy\n",
    "    U,S,Vt = np.linalg.svd(M, full_matrices=False)\n",
    "    corr = S[0] if len(S)>0 else np.nan\n",
    "    return float(corr)\n",
    "\n",
    "def run_ca(df):\n",
    "    labs = ['低','中','高'] if HAS_CHINESE_FONT else ['low','mid','high']\n",
    "    bins = pd.qcut(df['efficiency_score'], 3, labels=labs)\n",
    "    T = pd.crosstab(df['model'], bins)\n",
    "    N = T.values.astype(float)\n",
    "    n = N.sum()\n",
    "    P = N/n\n",
    "    r = P.sum(axis=1)\n",
    "    c = P.sum(axis=0)\n",
    "    Dr = np.diag(r)\n",
    "    Dc = np.diag(c)\n",
    "    Dri = np.diag(1/np.sqrt(np.maximum(r,1e-12)))\n",
    "    Dci = np.diag(1/np.sqrt(np.maximum(c,1e-12)))\n",
    "    S = Dri @ (P - np.outer(r,c)) @ Dci\n",
    "    U,Sig,Vt = np.linalg.svd(S, full_matrices=False)\n",
    "    F = Dri @ U @ np.diag(Sig)\n",
    "    G = Dci @ Vt.T @ np.diag(Sig)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    for i,name in enumerate(T.index):\n",
    "        plt.scatter(F[i,0], F[i,1], s=120)\n",
    "        plt.text(F[i,0], F[i,1], name)\n",
    "    for j,name in enumerate(T.columns):\n",
    "        plt.scatter(G[j,0], G[j,1], marker='x', s=120)\n",
    "        plt.text(G[j,0], G[j,1], str(name))\n",
    "    if HAS_CHINESE_FONT:\n",
    "        plt.title(\"对应分析\", fontproperties=FONT_PROP)\n",
    "    else:\n",
    "        plt.title(\"Correspondence Analysis\")\n",
    "    plt.savefig(os.path.join(FIGURES_DIR, \"ca_map.png\"))\n",
    "    plt.close()\n",
    "    return T, F, G, Sig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f270f99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    print(\"开始加载数据...\")\n",
    "    df_res, df_stats = load_data()\n",
    "    if df_res is None:\n",
    "        return\n",
    "\n",
    "    # 尝试合并细粒度质量指标\n",
    "    try:\n",
    "        df_quality = load_quality_details()\n",
    "        if not df_quality.empty:\n",
    "            # 简单合并，实际可能需要更复杂的对齐（这里假设 run 编号一致）\n",
    "            # 简化起见，若 task 和 run 匹配则更新\n",
    "            pass \n",
    "    except Exception as e:\n",
    "        print(f\"加载细粒度质量指标失败: {e}\")\n",
    "\n",
    "    print(\"计算复合指标...\")\n",
    "    df_analysis = calculate_composite_metrics(df_res)\n",
    "    \n",
    "    # 保存中间数据\n",
    "    df_analysis.to_csv(os.path.join(RESULTS_DIR, \"analysis_data.csv\"), index=False)\n",
    "    \n",
    "    print(\"生成图表...\")\n",
    "    try:\n",
    "        plot_charts(df_analysis)\n",
    "    except Exception as e:\n",
    "        print(f\"生成图表失败 (可能是字体或依赖问题): {e}\")\n",
    "    \n",
    "    print(\"生成报告...\")\n",
    "    generate_report(df_analysis, df_stats)\n",
    "    print(\"分析完成！\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
